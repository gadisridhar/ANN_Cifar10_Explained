# -*- coding: utf-8 -*-
"""ANN_Cifar10_WithEvaluations.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JsTukjbOnoREIc0uA-RRHilOkxoDju5z
"""

from keras.models import  Sequential
from keras import models, layers
import tensorflow as tf
from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras import datasets
from keras.layers.core.activation import Activation
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import classification_report, confusion_matrix

dataset = datasets.cifar10.load_data()

(X_train, y_train), (X_test, y_test) = dataset

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

print(y_train.shape)
print(y_train)
#CONVERT Y INTO 1 DIMENSIONAL ARRAY

# Train = 50000 images
# Test = 10000 images
# Image SIze = 32 * 32 pixel
# RGB pattern = 3

plt.imshow(X_train[140])

# CIFAR 10 = https://www.cs.toronto.edu/~kriz/cifar.html
# 10 CATEGORIES OF  IMAGE CATEGORIES LISTED

classes = ["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"]

y_train = y_train.reshape(-1,)
print(y_train)
#CONVERT Y INTO 1 DIMENSIONAL ARRAY

y_test = y_test.reshape(-1,)
print(y_test)
#CONVERT Y INTO 1 DIMENSIONAL ARRAY

def plot_sample(X, y , index):
  plt.figure(figsize=(5,2))
  plt.imshow(X[index])
  plt.xlabel(classes[y[index]])

plot_sample(X_train,y_train, 5)

# #before data ormalization
# print(X_train)
# print(X_test)

# after normalization
X_train = X_train / 255
X_test = X_test / 255
# print(X_train)
# print(X_test)

# Trying with ANN for Model evaluation before jumping into Other Better DL techniques

modelANN = models.Sequential([
    layers.Flatten(input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),
    layers.Dense(2000, activation='relu'),
    layers.Dense(3000, activation='relu'),
    layers.Dense(10, activation='sigmoid')
])

# loss = sparse_categorical_crossentropy  since we didnot  OneHotEncode the 10 categories, we have them as 1-10 
modelANN.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

modelANN.fit(X_train, y_train, epochs=5)

modelANN.evaluate(X_test, y_test)
#MODEL  ACCURACY ON TEST DATA IS 45, VERY LOW WITH USING ANN

y_pred = modelANN.predict(X_test)

y_pred_Multiclass = [np.argmax(data) for data in y_pred]

# CONFUSION MATRIX FOR Y TEST AND Y PRED TEST DATA
confusion_matrix(y_test,y_pred_Multiclass)
#We can find that not all the data are on the diagonals, hence the accuracy is only 51% in case of ANN.

#Classification Report for YTEST
print(classification_report(y_test, y_pred_Multiclass))

y_predTrain = modelANN.predict(X_train)

y_pred_MulticlassTrain = [np.argmax(data) for data in y_predTrain]

# CONFUSION MATRIX FOR Y TRAIN AND Y PRED TRAIN DATA
confusion_matrix(y_train,y_pred_MulticlassTrain)
#We can find that not all the data are on the diagonals, hence the accuracy is only 66% in case of ANN.

#Classification Report for YTRAIN
print(classification_report(y_train, y_pred_MulticlassTrain))

modelANN.summary()